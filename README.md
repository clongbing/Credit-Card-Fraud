# Credit-Card-Fraud
The aim is to produce a model that is able to accurately predict Fradulent vs Non-Fradulent transactions. Given the imbalanced dataset (very limited number of Fradulent transactions vs abundant Non-Fradulent transactions), ML models have very little Fradulent data to train on. To circumvent this, undersampling or oversampling methods are used to allow for better training performance, before the models are exposed to imbalanced datasets for actual testing (reflecting real-world situations).

In this project, I wanted to investigate the differences in performance of a few ML models with undersampling and oversampling methods with the use of an imbalanced dataset. 

Data used: Credit Card Fraud Detection Dataset from Kaggle - Anonymized credit card transactions labeled as fraudulent or genuine (https://www.kaggle.com/mlg-ulb/creditcardfraud)

## EDA on data
![image](https://user-images.githubusercontent.com/75196868/110233997-efb3e980-7f62-11eb-928d-b68fc4b58d42.png)
